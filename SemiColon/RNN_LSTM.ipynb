{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paresh/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "data = [[[(i + j) / 100] for i in range(5)] for j in range(100)]\n",
    "target = [(i + 5) / 100 for i in range(100)]\n",
    "\n",
    "data = np.array(data, dtype=float)\n",
    "target = np.array(target, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(data, target, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 5, 1)              12        \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 24\n",
      "Trainable params: 24\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN Model\n",
    "model = Sequential()\n",
    "model.add(LSTM((1), batch_input_shape=(None, 5, 1), return_sequences=True))\n",
    "model.add(LSTM((1), return_sequences=False))\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/400\n",
      "80/80 [==============================] - 1s 14ms/step - loss: 0.6716 - acc: 0.0000e+00 - val_loss: 0.5391 - val_acc: 0.0000e+00\n",
      "Epoch 2/400\n",
      "80/80 [==============================] - 0s 998us/step - loss: 0.6655 - acc: 0.0000e+00 - val_loss: 0.5330 - val_acc: 0.0000e+00\n",
      "Epoch 3/400\n",
      "80/80 [==============================] - 0s 638us/step - loss: 0.6591 - acc: 0.0000e+00 - val_loss: 0.5268 - val_acc: 0.0000e+00\n",
      "Epoch 4/400\n",
      "80/80 [==============================] - 0s 777us/step - loss: 0.6526 - acc: 0.0000e+00 - val_loss: 0.5207 - val_acc: 0.0000e+00\n",
      "Epoch 5/400\n",
      "80/80 [==============================] - 0s 652us/step - loss: 0.6461 - acc: 0.0000e+00 - val_loss: 0.5146 - val_acc: 0.0000e+00\n",
      "Epoch 6/400\n",
      "80/80 [==============================] - 0s 681us/step - loss: 0.6397 - acc: 0.0000e+00 - val_loss: 0.5087 - val_acc: 0.0000e+00\n",
      "Epoch 7/400\n",
      "80/80 [==============================] - 0s 675us/step - loss: 0.6335 - acc: 0.0000e+00 - val_loss: 0.5029 - val_acc: 0.0000e+00\n",
      "Epoch 8/400\n",
      "80/80 [==============================] - 0s 666us/step - loss: 0.6273 - acc: 0.0000e+00 - val_loss: 0.4972 - val_acc: 0.0000e+00\n",
      "Epoch 9/400\n",
      "80/80 [==============================] - 0s 700us/step - loss: 0.6213 - acc: 0.0000e+00 - val_loss: 0.4917 - val_acc: 0.0000e+00\n",
      "Epoch 10/400\n",
      "80/80 [==============================] - 0s 660us/step - loss: 0.6155 - acc: 0.0000e+00 - val_loss: 0.4862 - val_acc: 0.0000e+00\n",
      "Epoch 11/400\n",
      "80/80 [==============================] - 0s 708us/step - loss: 0.6098 - acc: 0.0000e+00 - val_loss: 0.4809 - val_acc: 0.0000e+00\n",
      "Epoch 12/400\n",
      "80/80 [==============================] - 0s 637us/step - loss: 0.6042 - acc: 0.0000e+00 - val_loss: 0.4758 - val_acc: 0.0000e+00\n",
      "Epoch 13/400\n",
      "80/80 [==============================] - 0s 946us/step - loss: 0.5987 - acc: 0.0000e+00 - val_loss: 0.4707 - val_acc: 0.0000e+00\n",
      "Epoch 14/400\n",
      "80/80 [==============================] - 0s 695us/step - loss: 0.5934 - acc: 0.0000e+00 - val_loss: 0.4658 - val_acc: 0.0000e+00\n",
      "Epoch 15/400\n",
      "80/80 [==============================] - 0s 633us/step - loss: 0.5882 - acc: 0.0000e+00 - val_loss: 0.4610 - val_acc: 0.0000e+00\n",
      "Epoch 16/400\n",
      "80/80 [==============================] - 0s 684us/step - loss: 0.5831 - acc: 0.0000e+00 - val_loss: 0.4563 - val_acc: 0.0000e+00\n",
      "Epoch 17/400\n",
      "80/80 [==============================] - 0s 607us/step - loss: 0.5783 - acc: 0.0000e+00 - val_loss: 0.4517 - val_acc: 0.0000e+00\n",
      "Epoch 18/400\n",
      "80/80 [==============================] - 0s 610us/step - loss: 0.5734 - acc: 0.0000e+00 - val_loss: 0.4471 - val_acc: 0.0000e+00\n",
      "Epoch 19/400\n",
      "80/80 [==============================] - 0s 610us/step - loss: 0.5688 - acc: 0.0000e+00 - val_loss: 0.4427 - val_acc: 0.0000e+00\n",
      "Epoch 20/400\n",
      "80/80 [==============================] - 0s 637us/step - loss: 0.5643 - acc: 0.0000e+00 - val_loss: 0.4383 - val_acc: 0.0000e+00\n",
      "Epoch 21/400\n",
      "80/80 [==============================] - 0s 618us/step - loss: 0.5599 - acc: 0.0000e+00 - val_loss: 0.4341 - val_acc: 0.0000e+00\n",
      "Epoch 22/400\n",
      "80/80 [==============================] - 0s 660us/step - loss: 0.5554 - acc: 0.0000e+00 - val_loss: 0.4302 - val_acc: 0.0000e+00\n",
      "Epoch 23/400\n",
      "80/80 [==============================] - 0s 666us/step - loss: 0.5512 - acc: 0.0000e+00 - val_loss: 0.4263 - val_acc: 0.0000e+00\n",
      "Epoch 24/400\n",
      "80/80 [==============================] - 0s 760us/step - loss: 0.5469 - acc: 0.0000e+00 - val_loss: 0.4224 - val_acc: 0.0000e+00\n",
      "Epoch 25/400\n",
      "80/80 [==============================] - 0s 792us/step - loss: 0.5427 - acc: 0.0000e+00 - val_loss: 0.4186 - val_acc: 0.0000e+00\n",
      "Epoch 26/400\n",
      "80/80 [==============================] - 0s 733us/step - loss: 0.5385 - acc: 0.0000e+00 - val_loss: 0.4148 - val_acc: 0.0000e+00\n",
      "Epoch 27/400\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.5345 - acc: 0.0000e+00 - val_loss: 0.4109 - val_acc: 0.0000e+00\n",
      "Epoch 28/400\n",
      "80/80 [==============================] - 0s 863us/step - loss: 0.5303 - acc: 0.0000e+00 - val_loss: 0.4072 - val_acc: 0.0000e+00\n",
      "Epoch 29/400\n",
      "80/80 [==============================] - 0s 718us/step - loss: 0.5263 - acc: 0.0000e+00 - val_loss: 0.4034 - val_acc: 0.0000e+00\n",
      "Epoch 30/400\n",
      "80/80 [==============================] - 0s 798us/step - loss: 0.5224 - acc: 0.0000e+00 - val_loss: 0.3997 - val_acc: 0.0000e+00\n",
      "Epoch 31/400\n",
      "80/80 [==============================] - 0s 752us/step - loss: 0.5185 - acc: 0.0000e+00 - val_loss: 0.3959 - val_acc: 0.0000e+00\n",
      "Epoch 32/400\n",
      "80/80 [==============================] - 0s 814us/step - loss: 0.5145 - acc: 0.0000e+00 - val_loss: 0.3921 - val_acc: 0.0000e+00\n",
      "Epoch 33/400\n",
      "80/80 [==============================] - 0s 716us/step - loss: 0.5106 - acc: 0.0000e+00 - val_loss: 0.3884 - val_acc: 0.0000e+00\n",
      "Epoch 34/400\n",
      "80/80 [==============================] - 0s 777us/step - loss: 0.5068 - acc: 0.0000e+00 - val_loss: 0.3846 - val_acc: 0.0000e+00\n",
      "Epoch 35/400\n",
      "80/80 [==============================] - 0s 965us/step - loss: 0.5030 - acc: 0.0000e+00 - val_loss: 0.3808 - val_acc: 0.0000e+00\n",
      "Epoch 36/400\n",
      "80/80 [==============================] - 0s 851us/step - loss: 0.4991 - acc: 0.0000e+00 - val_loss: 0.3770 - val_acc: 0.0000e+00\n",
      "Epoch 37/400\n",
      "80/80 [==============================] - 0s 936us/step - loss: 0.4954 - acc: 0.0000e+00 - val_loss: 0.3732 - val_acc: 0.0000e+00\n",
      "Epoch 38/400\n",
      "80/80 [==============================] - 0s 879us/step - loss: 0.4915 - acc: 0.0000e+00 - val_loss: 0.3694 - val_acc: 0.0000e+00\n",
      "Epoch 39/400\n",
      "80/80 [==============================] - 0s 710us/step - loss: 0.4878 - acc: 0.0000e+00 - val_loss: 0.3655 - val_acc: 0.0000e+00\n",
      "Epoch 40/400\n",
      "80/80 [==============================] - 0s 653us/step - loss: 0.4841 - acc: 0.0000e+00 - val_loss: 0.3615 - val_acc: 0.0000e+00\n",
      "Epoch 41/400\n",
      "80/80 [==============================] - 0s 710us/step - loss: 0.4801 - acc: 0.0000e+00 - val_loss: 0.3576 - val_acc: 0.0000e+00\n",
      "Epoch 42/400\n",
      "80/80 [==============================] - 0s 708us/step - loss: 0.4765 - acc: 0.0000e+00 - val_loss: 0.3537 - val_acc: 0.0000e+00\n",
      "Epoch 43/400\n",
      "80/80 [==============================] - 0s 722us/step - loss: 0.4727 - acc: 0.0000e+00 - val_loss: 0.3497 - val_acc: 0.0000e+00\n",
      "Epoch 44/400\n",
      "80/80 [==============================] - 0s 700us/step - loss: 0.4689 - acc: 0.0000e+00 - val_loss: 0.3457 - val_acc: 0.0000e+00\n",
      "Epoch 45/400\n",
      "80/80 [==============================] - 0s 764us/step - loss: 0.4652 - acc: 0.0000e+00 - val_loss: 0.3416 - val_acc: 0.0000e+00\n",
      "Epoch 46/400\n",
      "80/80 [==============================] - 0s 696us/step - loss: 0.4615 - acc: 0.0000e+00 - val_loss: 0.3376 - val_acc: 0.0000e+00\n",
      "Epoch 47/400\n",
      "80/80 [==============================] - 0s 751us/step - loss: 0.4579 - acc: 0.0000e+00 - val_loss: 0.3339 - val_acc: 0.0000e+00\n",
      "Epoch 48/400\n",
      "80/80 [==============================] - 0s 796us/step - loss: 0.4540 - acc: 0.0000e+00 - val_loss: 0.3303 - val_acc: 0.0000e+00\n",
      "Epoch 49/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.4503 - acc: 0.0000e+00 - val_loss: 0.3266 - val_acc: 0.0000e+00\n",
      "Epoch 50/400\n",
      "80/80 [==============================] - 0s 825us/step - loss: 0.4466 - acc: 0.0000e+00 - val_loss: 0.3228 - val_acc: 0.0000e+00\n",
      "Epoch 51/400\n",
      "80/80 [==============================] - 0s 979us/step - loss: 0.4429 - acc: 0.0000e+00 - val_loss: 0.3190 - val_acc: 0.0000e+00\n",
      "Epoch 52/400\n",
      "80/80 [==============================] - 0s 870us/step - loss: 0.4392 - acc: 0.0000e+00 - val_loss: 0.3153 - val_acc: 0.0000e+00\n",
      "Epoch 53/400\n",
      "80/80 [==============================] - 0s 900us/step - loss: 0.4357 - acc: 0.0000e+00 - val_loss: 0.3115 - val_acc: 0.0000e+00\n",
      "Epoch 54/400\n",
      "80/80 [==============================] - 0s 942us/step - loss: 0.4318 - acc: 0.0000e+00 - val_loss: 0.3079 - val_acc: 0.0000e+00\n",
      "Epoch 55/400\n",
      "80/80 [==============================] - 0s 887us/step - loss: 0.4283 - acc: 0.0000e+00 - val_loss: 0.3045 - val_acc: 0.0000e+00\n",
      "Epoch 56/400\n",
      "80/80 [==============================] - 0s 834us/step - loss: 0.4245 - acc: 0.0000e+00 - val_loss: 0.3011 - val_acc: 0.0000e+00\n",
      "Epoch 57/400\n",
      "80/80 [==============================] - 0s 682us/step - loss: 0.4209 - acc: 0.0000e+00 - val_loss: 0.2979 - val_acc: 0.0000e+00\n",
      "Epoch 58/400\n",
      "80/80 [==============================] - 0s 735us/step - loss: 0.4171 - acc: 0.0000e+00 - val_loss: 0.2948 - val_acc: 0.0000e+00\n",
      "Epoch 59/400\n",
      "80/80 [==============================] - 0s 693us/step - loss: 0.4132 - acc: 0.0000e+00 - val_loss: 0.2917 - val_acc: 0.0000e+00\n",
      "Epoch 60/400\n",
      "80/80 [==============================] - 0s 697us/step - loss: 0.4095 - acc: 0.0000e+00 - val_loss: 0.2886 - val_acc: 0.0000e+00\n",
      "Epoch 61/400\n",
      "80/80 [==============================] - 0s 715us/step - loss: 0.4058 - acc: 0.0000e+00 - val_loss: 0.2855 - val_acc: 0.0000e+00\n",
      "Epoch 62/400\n",
      "80/80 [==============================] - 0s 715us/step - loss: 0.4019 - acc: 0.0000e+00 - val_loss: 0.2828 - val_acc: 0.0000e+00\n",
      "Epoch 63/400\n",
      "80/80 [==============================] - 0s 716us/step - loss: 0.3983 - acc: 0.0000e+00 - val_loss: 0.2801 - val_acc: 0.0000e+00\n",
      "Epoch 64/400\n",
      "80/80 [==============================] - 0s 764us/step - loss: 0.3947 - acc: 0.0000e+00 - val_loss: 0.2774 - val_acc: 0.0000e+00\n",
      "Epoch 65/400\n",
      "80/80 [==============================] - 0s 665us/step - loss: 0.3907 - acc: 0.0000e+00 - val_loss: 0.2747 - val_acc: 0.0000e+00\n",
      "Epoch 66/400\n",
      "80/80 [==============================] - 0s 757us/step - loss: 0.3873 - acc: 0.0000e+00 - val_loss: 0.2721 - val_acc: 0.0000e+00\n",
      "Epoch 67/400\n",
      "80/80 [==============================] - 0s 793us/step - loss: 0.3838 - acc: 0.0000e+00 - val_loss: 0.2694 - val_acc: 0.0000e+00\n",
      "Epoch 68/400\n",
      "80/80 [==============================] - 0s 925us/step - loss: 0.3801 - acc: 0.0000e+00 - val_loss: 0.2668 - val_acc: 0.0000e+00\n",
      "Epoch 69/400\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3768 - acc: 0.0000e+00 - val_loss: 0.2642 - val_acc: 0.0000e+00\n",
      "Epoch 70/400\n",
      "80/80 [==============================] - 0s 899us/step - loss: 0.3737 - acc: 0.0000e+00 - val_loss: 0.2616 - val_acc: 0.0000e+00\n",
      "Epoch 71/400\n",
      "80/80 [==============================] - 0s 838us/step - loss: 0.3703 - acc: 0.0000e+00 - val_loss: 0.2593 - val_acc: 0.0000e+00\n",
      "Epoch 72/400\n",
      "80/80 [==============================] - 0s 696us/step - loss: 0.3669 - acc: 0.0000e+00 - val_loss: 0.2572 - val_acc: 0.0000e+00\n",
      "Epoch 73/400\n",
      "80/80 [==============================] - 0s 812us/step - loss: 0.3634 - acc: 0.0000e+00 - val_loss: 0.2551 - val_acc: 0.0000e+00\n",
      "Epoch 74/400\n",
      "80/80 [==============================] - 0s 835us/step - loss: 0.3603 - acc: 0.0000e+00 - val_loss: 0.2529 - val_acc: 0.0000e+00\n",
      "Epoch 75/400\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.3571 - acc: 0.0000e+00 - val_loss: 0.2507 - val_acc: 0.0000e+00\n",
      "Epoch 76/400\n",
      "80/80 [==============================] - 0s 896us/step - loss: 0.3538 - acc: 0.0000e+00 - val_loss: 0.2485 - val_acc: 0.0000e+00\n",
      "Epoch 77/400\n",
      "80/80 [==============================] - 0s 722us/step - loss: 0.3507 - acc: 0.0000e+00 - val_loss: 0.2463 - val_acc: 0.0000e+00\n",
      "Epoch 78/400\n",
      "80/80 [==============================] - 0s 944us/step - loss: 0.3478 - acc: 0.0000e+00 - val_loss: 0.2442 - val_acc: 0.0000e+00\n",
      "Epoch 79/400\n",
      "80/80 [==============================] - 0s 652us/step - loss: 0.3450 - acc: 0.0000e+00 - val_loss: 0.2420 - val_acc: 0.0000e+00\n",
      "Epoch 80/400\n",
      "80/80 [==============================] - 0s 644us/step - loss: 0.3417 - acc: 0.0000e+00 - val_loss: 0.2403 - val_acc: 0.0000e+00\n",
      "Epoch 81/400\n",
      "80/80 [==============================] - 0s 610us/step - loss: 0.3392 - acc: 0.0000e+00 - val_loss: 0.2387 - val_acc: 0.0000e+00\n",
      "Epoch 82/400\n",
      "80/80 [==============================] - 0s 631us/step - loss: 0.3363 - acc: 0.0000e+00 - val_loss: 0.2371 - val_acc: 0.0000e+00\n",
      "Epoch 83/400\n",
      "80/80 [==============================] - 0s 630us/step - loss: 0.3335 - acc: 0.0000e+00 - val_loss: 0.2355 - val_acc: 0.0000e+00\n",
      "Epoch 84/400\n",
      "80/80 [==============================] - 0s 646us/step - loss: 0.3308 - acc: 0.0000e+00 - val_loss: 0.2339 - val_acc: 0.0000e+00\n",
      "Epoch 85/400\n",
      "80/80 [==============================] - 0s 734us/step - loss: 0.3283 - acc: 0.0000e+00 - val_loss: 0.2327 - val_acc: 0.0000e+00\n",
      "Epoch 86/400\n",
      "80/80 [==============================] - 0s 779us/step - loss: 0.3254 - acc: 0.0000e+00 - val_loss: 0.2316 - val_acc: 0.0000e+00\n",
      "Epoch 87/400\n",
      "80/80 [==============================] - 0s 793us/step - loss: 0.3230 - acc: 0.0000e+00 - val_loss: 0.2304 - val_acc: 0.0000e+00\n",
      "Epoch 88/400\n",
      "80/80 [==============================] - 0s 874us/step - loss: 0.3204 - acc: 0.0000e+00 - val_loss: 0.2293 - val_acc: 0.0000e+00\n",
      "Epoch 89/400\n",
      "80/80 [==============================] - 0s 854us/step - loss: 0.3177 - acc: 0.0000e+00 - val_loss: 0.2282 - val_acc: 0.0000e+00\n",
      "Epoch 90/400\n",
      "80/80 [==============================] - 0s 944us/step - loss: 0.3157 - acc: 0.0000e+00 - val_loss: 0.2270 - val_acc: 0.0000e+00\n",
      "Epoch 91/400\n",
      "80/80 [==============================] - 0s 987us/step - loss: 0.3129 - acc: 0.0000e+00 - val_loss: 0.2260 - val_acc: 0.0000e+00\n",
      "Epoch 92/400\n",
      "80/80 [==============================] - 0s 866us/step - loss: 0.3108 - acc: 0.0000e+00 - val_loss: 0.2251 - val_acc: 0.0000e+00\n",
      "Epoch 93/400\n",
      "80/80 [==============================] - 0s 774us/step - loss: 0.3085 - acc: 0.0000e+00 - val_loss: 0.2244 - val_acc: 0.0000e+00\n",
      "Epoch 94/400\n",
      "80/80 [==============================] - 0s 750us/step - loss: 0.3059 - acc: 0.0000e+00 - val_loss: 0.2238 - val_acc: 0.0000e+00\n",
      "Epoch 95/400\n",
      "80/80 [==============================] - 0s 772us/step - loss: 0.3040 - acc: 0.0000e+00 - val_loss: 0.2231 - val_acc: 0.0000e+00\n",
      "Epoch 96/400\n",
      "80/80 [==============================] - 0s 759us/step - loss: 0.3018 - acc: 0.0000e+00 - val_loss: 0.2224 - val_acc: 0.0000e+00\n",
      "Epoch 97/400\n",
      "80/80 [==============================] - 0s 712us/step - loss: 0.2997 - acc: 0.0000e+00 - val_loss: 0.2218 - val_acc: 0.0000e+00\n",
      "Epoch 98/400\n",
      "80/80 [==============================] - 0s 769us/step - loss: 0.2975 - acc: 0.0000e+00 - val_loss: 0.2211 - val_acc: 0.0000e+00\n",
      "Epoch 99/400\n",
      "80/80 [==============================] - 0s 767us/step - loss: 0.2954 - acc: 0.0000e+00 - val_loss: 0.2205 - val_acc: 0.0000e+00\n",
      "Epoch 100/400\n",
      "80/80 [==============================] - 0s 768us/step - loss: 0.2937 - acc: 0.0000e+00 - val_loss: 0.2199 - val_acc: 0.0000e+00\n",
      "Epoch 101/400\n",
      "80/80 [==============================] - 0s 812us/step - loss: 0.2919 - acc: 0.0000e+00 - val_loss: 0.2192 - val_acc: 0.0000e+00\n",
      "Epoch 102/400\n",
      "80/80 [==============================] - 0s 797us/step - loss: 0.2900 - acc: 0.0000e+00 - val_loss: 0.2186 - val_acc: 0.0000e+00\n",
      "Epoch 103/400\n",
      "80/80 [==============================] - 0s 888us/step - loss: 0.2883 - acc: 0.0000e+00 - val_loss: 0.2180 - val_acc: 0.0000e+00\n",
      "Epoch 104/400\n",
      "80/80 [==============================] - 0s 714us/step - loss: 0.2866 - acc: 0.0000e+00 - val_loss: 0.2174 - val_acc: 0.0000e+00\n",
      "Epoch 105/400\n",
      "80/80 [==============================] - 0s 831us/step - loss: 0.2849 - acc: 0.0000e+00 - val_loss: 0.2168 - val_acc: 0.0000e+00\n",
      "Epoch 106/400\n",
      "80/80 [==============================] - 0s 780us/step - loss: 0.2834 - acc: 0.0000e+00 - val_loss: 0.2162 - val_acc: 0.0000e+00\n",
      "Epoch 107/400\n",
      "80/80 [==============================] - 0s 745us/step - loss: 0.2819 - acc: 0.0000e+00 - val_loss: 0.2157 - val_acc: 0.0000e+00\n",
      "Epoch 108/400\n",
      "80/80 [==============================] - 0s 843us/step - loss: 0.2803 - acc: 0.0000e+00 - val_loss: 0.2154 - val_acc: 0.0000e+00\n",
      "Epoch 109/400\n",
      "80/80 [==============================] - 0s 754us/step - loss: 0.2790 - acc: 0.0000e+00 - val_loss: 0.2152 - val_acc: 0.0000e+00\n",
      "Epoch 110/400\n",
      "80/80 [==============================] - 0s 865us/step - loss: 0.2776 - acc: 0.0000e+00 - val_loss: 0.2149 - val_acc: 0.0000e+00\n",
      "Epoch 111/400\n",
      "80/80 [==============================] - 0s 812us/step - loss: 0.2760 - acc: 0.0000e+00 - val_loss: 0.2147 - val_acc: 0.0000e+00\n",
      "Epoch 112/400\n",
      "80/80 [==============================] - 0s 799us/step - loss: 0.2747 - acc: 0.0000e+00 - val_loss: 0.2145 - val_acc: 0.0000e+00\n",
      "Epoch 113/400\n",
      "80/80 [==============================] - 0s 643us/step - loss: 0.2734 - acc: 0.0000e+00 - val_loss: 0.2143 - val_acc: 0.0000e+00\n",
      "Epoch 114/400\n",
      "80/80 [==============================] - 0s 756us/step - loss: 0.2721 - acc: 0.0000e+00 - val_loss: 0.2144 - val_acc: 0.0000e+00\n",
      "Epoch 115/400\n",
      "80/80 [==============================] - 0s 692us/step - loss: 0.2708 - acc: 0.0000e+00 - val_loss: 0.2144 - val_acc: 0.0000e+00\n",
      "Epoch 116/400\n",
      "80/80 [==============================] - 0s 811us/step - loss: 0.2696 - acc: 0.0000e+00 - val_loss: 0.2145 - val_acc: 0.0000e+00\n",
      "Epoch 117/400\n",
      "80/80 [==============================] - 0s 768us/step - loss: 0.2684 - acc: 0.0000e+00 - val_loss: 0.2146 - val_acc: 0.0000e+00\n",
      "Epoch 118/400\n",
      "80/80 [==============================] - 0s 796us/step - loss: 0.2670 - acc: 0.0000e+00 - val_loss: 0.2147 - val_acc: 0.0000e+00\n",
      "Epoch 119/400\n",
      "80/80 [==============================] - 0s 687us/step - loss: 0.2659 - acc: 0.0000e+00 - val_loss: 0.2148 - val_acc: 0.0000e+00\n",
      "Epoch 120/400\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.2649 - acc: 0.0000e+00 - val_loss: 0.2149 - val_acc: 0.0000e+00\n",
      "Epoch 121/400\n",
      "80/80 [==============================] - 0s 746us/step - loss: 0.2637 - acc: 0.0000e+00 - val_loss: 0.2149 - val_acc: 0.0000e+00\n",
      "Epoch 122/400\n",
      "80/80 [==============================] - 0s 744us/step - loss: 0.2628 - acc: 0.0000e+00 - val_loss: 0.2150 - val_acc: 0.0000e+00\n",
      "Epoch 123/400\n",
      "80/80 [==============================] - 0s 769us/step - loss: 0.2615 - acc: 0.0000e+00 - val_loss: 0.2151 - val_acc: 0.0000e+00\n",
      "Epoch 124/400\n",
      "80/80 [==============================] - 0s 774us/step - loss: 0.2605 - acc: 0.0000e+00 - val_loss: 0.2152 - val_acc: 0.0000e+00\n",
      "Epoch 125/400\n",
      "80/80 [==============================] - 0s 796us/step - loss: 0.2595 - acc: 0.0000e+00 - val_loss: 0.2152 - val_acc: 0.0000e+00\n",
      "Epoch 126/400\n",
      "80/80 [==============================] - 0s 709us/step - loss: 0.2586 - acc: 0.0000e+00 - val_loss: 0.2153 - val_acc: 0.0000e+00\n",
      "Epoch 127/400\n",
      "80/80 [==============================] - 0s 728us/step - loss: 0.2578 - acc: 0.0000e+00 - val_loss: 0.2156 - val_acc: 0.0000e+00\n",
      "Epoch 128/400\n",
      "80/80 [==============================] - 0s 835us/step - loss: 0.2567 - acc: 0.0000e+00 - val_loss: 0.2159 - val_acc: 0.0000e+00\n",
      "Epoch 129/400\n",
      "80/80 [==============================] - 0s 711us/step - loss: 0.2559 - acc: 0.0000e+00 - val_loss: 0.2161 - val_acc: 0.0000e+00\n",
      "Epoch 130/400\n",
      "80/80 [==============================] - 0s 727us/step - loss: 0.2549 - acc: 0.0000e+00 - val_loss: 0.2164 - val_acc: 0.0000e+00\n",
      "Epoch 131/400\n",
      "80/80 [==============================] - 0s 784us/step - loss: 0.2542 - acc: 0.0000e+00 - val_loss: 0.2167 - val_acc: 0.0000e+00\n",
      "Epoch 132/400\n",
      "80/80 [==============================] - 0s 824us/step - loss: 0.2534 - acc: 0.0000e+00 - val_loss: 0.2169 - val_acc: 0.0000e+00\n",
      "Epoch 133/400\n",
      "80/80 [==============================] - 0s 702us/step - loss: 0.2527 - acc: 0.0000e+00 - val_loss: 0.2172 - val_acc: 0.0000e+00\n",
      "Epoch 134/400\n",
      "80/80 [==============================] - 0s 725us/step - loss: 0.2518 - acc: 0.0000e+00 - val_loss: 0.2175 - val_acc: 0.0000e+00\n",
      "Epoch 135/400\n",
      "80/80 [==============================] - 0s 675us/step - loss: 0.2509 - acc: 0.0000e+00 - val_loss: 0.2180 - val_acc: 0.0000e+00\n",
      "Epoch 136/400\n",
      "80/80 [==============================] - 0s 659us/step - loss: 0.2502 - acc: 0.0000e+00 - val_loss: 0.2185 - val_acc: 0.0500\n",
      "Epoch 137/400\n",
      "80/80 [==============================] - 0s 787us/step - loss: 0.2494 - acc: 0.0000e+00 - val_loss: 0.2190 - val_acc: 0.0500\n",
      "Epoch 138/400\n",
      "80/80 [==============================] - 0s 751us/step - loss: 0.2485 - acc: 0.0000e+00 - val_loss: 0.2195 - val_acc: 0.0500\n",
      "Epoch 139/400\n",
      "80/80 [==============================] - 0s 666us/step - loss: 0.2478 - acc: 0.0000e+00 - val_loss: 0.2200 - val_acc: 0.0500\n",
      "Epoch 140/400\n",
      "80/80 [==============================] - 0s 676us/step - loss: 0.2471 - acc: 0.0000e+00 - val_loss: 0.2205 - val_acc: 0.0500\n",
      "Epoch 141/400\n",
      "80/80 [==============================] - 0s 819us/step - loss: 0.2465 - acc: 0.0000e+00 - val_loss: 0.2209 - val_acc: 0.0500\n",
      "Epoch 142/400\n",
      "80/80 [==============================] - 0s 728us/step - loss: 0.2456 - acc: 0.0000e+00 - val_loss: 0.2213 - val_acc: 0.0500\n",
      "Epoch 143/400\n",
      "80/80 [==============================] - 0s 685us/step - loss: 0.2451 - acc: 0.0000e+00 - val_loss: 0.2217 - val_acc: 0.0500\n",
      "Epoch 144/400\n",
      "80/80 [==============================] - 0s 647us/step - loss: 0.2444 - acc: 0.0000e+00 - val_loss: 0.2221 - val_acc: 0.0500\n",
      "Epoch 145/400\n",
      "80/80 [==============================] - 0s 757us/step - loss: 0.2437 - acc: 0.0000e+00 - val_loss: 0.2224 - val_acc: 0.0500\n",
      "Epoch 146/400\n",
      "80/80 [==============================] - 0s 797us/step - loss: 0.2431 - acc: 0.0000e+00 - val_loss: 0.2227 - val_acc: 0.0500\n",
      "Epoch 147/400\n",
      "80/80 [==============================] - 0s 698us/step - loss: 0.2425 - acc: 0.0000e+00 - val_loss: 0.2231 - val_acc: 0.0500\n",
      "Epoch 148/400\n",
      "80/80 [==============================] - 0s 743us/step - loss: 0.2421 - acc: 0.0000e+00 - val_loss: 0.2235 - val_acc: 0.0500\n",
      "Epoch 149/400\n",
      "80/80 [==============================] - 0s 754us/step - loss: 0.2414 - acc: 0.0000e+00 - val_loss: 0.2238 - val_acc: 0.0500\n",
      "Epoch 150/400\n",
      "80/80 [==============================] - 0s 673us/step - loss: 0.2408 - acc: 0.0000e+00 - val_loss: 0.2242 - val_acc: 0.0500\n",
      "Epoch 151/400\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.2403 - acc: 0.0000e+00 - val_loss: 0.2245 - val_acc: 0.0500\n",
      "Epoch 152/400\n",
      "80/80 [==============================] - 0s 682us/step - loss: 0.2397 - acc: 0.0000e+00 - val_loss: 0.2250 - val_acc: 0.0500\n",
      "Epoch 153/400\n",
      "80/80 [==============================] - 0s 777us/step - loss: 0.2391 - acc: 0.0000e+00 - val_loss: 0.2255 - val_acc: 0.0500\n",
      "Epoch 154/400\n",
      "80/80 [==============================] - 0s 725us/step - loss: 0.2386 - acc: 0.0000e+00 - val_loss: 0.2259 - val_acc: 0.0500\n",
      "Epoch 155/400\n",
      "80/80 [==============================] - 0s 794us/step - loss: 0.2380 - acc: 0.0000e+00 - val_loss: 0.2264 - val_acc: 0.0500\n",
      "Epoch 156/400\n",
      "80/80 [==============================] - 0s 773us/step - loss: 0.2374 - acc: 0.0000e+00 - val_loss: 0.2268 - val_acc: 0.0500\n",
      "Epoch 157/400\n",
      "80/80 [==============================] - 0s 745us/step - loss: 0.2369 - acc: 0.0000e+00 - val_loss: 0.2272 - val_acc: 0.0500\n",
      "Epoch 158/400\n",
      "80/80 [==============================] - 0s 730us/step - loss: 0.2364 - acc: 0.0000e+00 - val_loss: 0.2277 - val_acc: 0.0500\n",
      "Epoch 159/400\n",
      "80/80 [==============================] - 0s 685us/step - loss: 0.2358 - acc: 0.0000e+00 - val_loss: 0.2280 - val_acc: 0.0500\n",
      "Epoch 160/400\n",
      "80/80 [==============================] - 0s 716us/step - loss: 0.2353 - acc: 0.0000e+00 - val_loss: 0.2284 - val_acc: 0.0500\n",
      "Epoch 161/400\n",
      "80/80 [==============================] - 0s 666us/step - loss: 0.2348 - acc: 0.0000e+00 - val_loss: 0.2287 - val_acc: 0.0500\n",
      "Epoch 162/400\n",
      "80/80 [==============================] - 0s 702us/step - loss: 0.2343 - acc: 0.0000e+00 - val_loss: 0.2291 - val_acc: 0.0500\n",
      "Epoch 163/400\n",
      "80/80 [==============================] - 0s 771us/step - loss: 0.2338 - acc: 0.0000e+00 - val_loss: 0.2294 - val_acc: 0.0500\n",
      "Epoch 164/400\n",
      "80/80 [==============================] - 0s 730us/step - loss: 0.2334 - acc: 0.0000e+00 - val_loss: 0.2297 - val_acc: 0.0500\n",
      "Epoch 165/400\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.2329 - acc: 0.0000e+00 - val_loss: 0.2300 - val_acc: 0.0500\n",
      "Epoch 166/400\n",
      "80/80 [==============================] - 0s 685us/step - loss: 0.2323 - acc: 0.0000e+00 - val_loss: 0.2303 - val_acc: 0.0500\n",
      "Epoch 167/400\n",
      "80/80 [==============================] - 0s 812us/step - loss: 0.2319 - acc: 0.0000e+00 - val_loss: 0.2306 - val_acc: 0.0500\n",
      "Epoch 168/400\n",
      "80/80 [==============================] - 0s 738us/step - loss: 0.2314 - acc: 0.0000e+00 - val_loss: 0.2309 - val_acc: 0.0500\n",
      "Epoch 169/400\n",
      "80/80 [==============================] - 0s 688us/step - loss: 0.2309 - acc: 0.0000e+00 - val_loss: 0.2312 - val_acc: 0.0500\n",
      "Epoch 170/400\n",
      "80/80 [==============================] - 0s 781us/step - loss: 0.2304 - acc: 0.0000e+00 - val_loss: 0.2315 - val_acc: 0.0500\n",
      "Epoch 171/400\n",
      "80/80 [==============================] - 0s 809us/step - loss: 0.2299 - acc: 0.0000e+00 - val_loss: 0.2317 - val_acc: 0.0500\n",
      "Epoch 172/400\n",
      "80/80 [==============================] - 0s 771us/step - loss: 0.2295 - acc: 0.0000e+00 - val_loss: 0.2319 - val_acc: 0.0500\n",
      "Epoch 173/400\n",
      "80/80 [==============================] - 0s 727us/step - loss: 0.2291 - acc: 0.0000e+00 - val_loss: 0.2321 - val_acc: 0.0500\n",
      "Epoch 174/400\n",
      "80/80 [==============================] - 0s 797us/step - loss: 0.2285 - acc: 0.0000e+00 - val_loss: 0.2322 - val_acc: 0.0500\n",
      "Epoch 175/400\n",
      "80/80 [==============================] - 0s 839us/step - loss: 0.2282 - acc: 0.0000e+00 - val_loss: 0.2323 - val_acc: 0.0500\n",
      "Epoch 176/400\n",
      "80/80 [==============================] - 0s 707us/step - loss: 0.2276 - acc: 0.0000e+00 - val_loss: 0.2322 - val_acc: 0.0500\n",
      "Epoch 177/400\n",
      "80/80 [==============================] - 0s 667us/step - loss: 0.2272 - acc: 0.0000e+00 - val_loss: 0.2321 - val_acc: 0.0500\n",
      "Epoch 178/400\n",
      "80/80 [==============================] - 0s 723us/step - loss: 0.2268 - acc: 0.0000e+00 - val_loss: 0.2320 - val_acc: 0.0500\n",
      "Epoch 179/400\n",
      "80/80 [==============================] - 0s 734us/step - loss: 0.2264 - acc: 0.0000e+00 - val_loss: 0.2320 - val_acc: 0.0500\n",
      "Epoch 180/400\n",
      "80/80 [==============================] - 0s 688us/step - loss: 0.2259 - acc: 0.0000e+00 - val_loss: 0.2319 - val_acc: 0.0500\n",
      "Epoch 181/400\n",
      "80/80 [==============================] - 0s 642us/step - loss: 0.2254 - acc: 0.0000e+00 - val_loss: 0.2319 - val_acc: 0.0500\n",
      "Epoch 182/400\n",
      "80/80 [==============================] - 0s 659us/step - loss: 0.2250 - acc: 0.0000e+00 - val_loss: 0.2319 - val_acc: 0.0500\n",
      "Epoch 183/400\n",
      "80/80 [==============================] - 0s 763us/step - loss: 0.2245 - acc: 0.0000e+00 - val_loss: 0.2319 - val_acc: 0.0500\n",
      "Epoch 184/400\n",
      "80/80 [==============================] - 0s 716us/step - loss: 0.2240 - acc: 0.0000e+00 - val_loss: 0.2320 - val_acc: 0.0500\n",
      "Epoch 185/400\n",
      "80/80 [==============================] - 0s 735us/step - loss: 0.2235 - acc: 0.0000e+00 - val_loss: 0.2319 - val_acc: 0.0500\n",
      "Epoch 186/400\n",
      "80/80 [==============================] - 0s 577us/step - loss: 0.2230 - acc: 0.0000e+00 - val_loss: 0.2318 - val_acc: 0.0500\n",
      "Epoch 187/400\n",
      "80/80 [==============================] - 0s 701us/step - loss: 0.2225 - acc: 0.0000e+00 - val_loss: 0.2316 - val_acc: 0.0500\n",
      "Epoch 188/400\n",
      "80/80 [==============================] - 0s 565us/step - loss: 0.2220 - acc: 0.0000e+00 - val_loss: 0.2314 - val_acc: 0.0500\n",
      "Epoch 189/400\n",
      "80/80 [==============================] - 0s 677us/step - loss: 0.2215 - acc: 0.0000e+00 - val_loss: 0.2312 - val_acc: 0.0500\n",
      "Epoch 190/400\n",
      "80/80 [==============================] - 0s 610us/step - loss: 0.2209 - acc: 0.0000e+00 - val_loss: 0.2311 - val_acc: 0.0500\n",
      "Epoch 191/400\n",
      "80/80 [==============================] - 0s 638us/step - loss: 0.2204 - acc: 0.0000e+00 - val_loss: 0.2310 - val_acc: 0.0500\n",
      "Epoch 192/400\n",
      "80/80 [==============================] - 0s 688us/step - loss: 0.2200 - acc: 0.0000e+00 - val_loss: 0.2310 - val_acc: 0.0500\n",
      "Epoch 193/400\n",
      "80/80 [==============================] - 0s 608us/step - loss: 0.2193 - acc: 0.0000e+00 - val_loss: 0.2308 - val_acc: 0.0500\n",
      "Epoch 194/400\n",
      "80/80 [==============================] - 0s 670us/step - loss: 0.2187 - acc: 0.0000e+00 - val_loss: 0.2306 - val_acc: 0.0500\n",
      "Epoch 195/400\n",
      "80/80 [==============================] - 0s 719us/step - loss: 0.2181 - acc: 0.0000e+00 - val_loss: 0.2304 - val_acc: 0.0500\n",
      "Epoch 196/400\n",
      "80/80 [==============================] - 0s 664us/step - loss: 0.2175 - acc: 0.0000e+00 - val_loss: 0.2303 - val_acc: 0.0500\n",
      "Epoch 197/400\n",
      "80/80 [==============================] - 0s 896us/step - loss: 0.2169 - acc: 0.0000e+00 - val_loss: 0.2301 - val_acc: 0.0500\n",
      "Epoch 198/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2163 - acc: 0.0000e+00 - val_loss: 0.2299 - val_acc: 0.0500\n",
      "Epoch 199/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2156 - acc: 0.0000e+00 - val_loss: 0.2296 - val_acc: 0.0500\n",
      "Epoch 200/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2149 - acc: 0.0000e+00 - val_loss: 0.2293 - val_acc: 0.0500\n",
      "Epoch 201/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2142 - acc: 0.0000e+00 - val_loss: 0.2291 - val_acc: 0.0500\n",
      "Epoch 202/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2136 - acc: 0.0000e+00 - val_loss: 0.2290 - val_acc: 0.0500\n",
      "Epoch 203/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2128 - acc: 0.0000e+00 - val_loss: 0.2288 - val_acc: 0.0500\n",
      "Epoch 204/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2120 - acc: 0.0000e+00 - val_loss: 0.2287 - val_acc: 0.0500\n",
      "Epoch 205/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2112 - acc: 0.0000e+00 - val_loss: 0.2286 - val_acc: 0.0500\n",
      "Epoch 206/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2105 - acc: 0.0000e+00 - val_loss: 0.2285 - val_acc: 0.0500\n",
      "Epoch 207/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2096 - acc: 0.0000e+00 - val_loss: 0.2283 - val_acc: 0.0500\n",
      "Epoch 208/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2087 - acc: 0.0000e+00 - val_loss: 0.2280 - val_acc: 0.0500\n",
      "Epoch 209/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2080 - acc: 0.0000e+00 - val_loss: 0.2280 - val_acc: 0.0500\n",
      "Epoch 210/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2070 - acc: 0.0000e+00 - val_loss: 0.2277 - val_acc: 0.0500\n",
      "Epoch 211/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2061 - acc: 0.0000e+00 - val_loss: 0.2274 - val_acc: 0.0500\n",
      "Epoch 212/400\n",
      "80/80 [==============================] - 0s 614us/step - loss: 0.2052 - acc: 0.0000e+00 - val_loss: 0.2269 - val_acc: 0.0500\n",
      "Epoch 213/400\n",
      "80/80 [==============================] - 0s 660us/step - loss: 0.2043 - acc: 0.0000e+00 - val_loss: 0.2264 - val_acc: 0.0500\n",
      "Epoch 214/400\n",
      "80/80 [==============================] - 0s 671us/step - loss: 0.2033 - acc: 0.0000e+00 - val_loss: 0.2259 - val_acc: 0.0500\n",
      "Epoch 215/400\n",
      "80/80 [==============================] - 0s 652us/step - loss: 0.2024 - acc: 0.0000e+00 - val_loss: 0.2254 - val_acc: 0.0500\n",
      "Epoch 216/400\n",
      "80/80 [==============================] - 0s 562us/step - loss: 0.2013 - acc: 0.0000e+00 - val_loss: 0.2248 - val_acc: 0.0500\n",
      "Epoch 217/400\n",
      "80/80 [==============================] - 0s 650us/step - loss: 0.2003 - acc: 0.0000e+00 - val_loss: 0.2241 - val_acc: 0.0500\n",
      "Epoch 218/400\n",
      "80/80 [==============================] - 0s 755us/step - loss: 0.1993 - acc: 0.0000e+00 - val_loss: 0.2234 - val_acc: 0.0500\n",
      "Epoch 219/400\n",
      "80/80 [==============================] - 0s 574us/step - loss: 0.1983 - acc: 0.0000e+00 - val_loss: 0.2227 - val_acc: 0.0500\n",
      "Epoch 220/400\n",
      "80/80 [==============================] - 0s 600us/step - loss: 0.1971 - acc: 0.0000e+00 - val_loss: 0.2217 - val_acc: 0.0500\n",
      "Epoch 221/400\n",
      "80/80 [==============================] - 0s 555us/step - loss: 0.1960 - acc: 0.0000e+00 - val_loss: 0.2206 - val_acc: 0.0500\n",
      "Epoch 222/400\n",
      "80/80 [==============================] - 0s 594us/step - loss: 0.1949 - acc: 0.0000e+00 - val_loss: 0.2197 - val_acc: 0.0500\n",
      "Epoch 223/400\n",
      "80/80 [==============================] - 0s 718us/step - loss: 0.1937 - acc: 0.0000e+00 - val_loss: 0.2188 - val_acc: 0.0500\n",
      "Epoch 224/400\n",
      "80/80 [==============================] - 0s 593us/step - loss: 0.1924 - acc: 0.0000e+00 - val_loss: 0.2177 - val_acc: 0.0500\n",
      "Epoch 225/400\n",
      "80/80 [==============================] - 0s 620us/step - loss: 0.1912 - acc: 0.0000e+00 - val_loss: 0.2164 - val_acc: 0.0500\n",
      "Epoch 226/400\n",
      "80/80 [==============================] - 0s 624us/step - loss: 0.1899 - acc: 0.0000e+00 - val_loss: 0.2153 - val_acc: 0.0500\n",
      "Epoch 227/400\n",
      "80/80 [==============================] - 0s 667us/step - loss: 0.1886 - acc: 0.0000e+00 - val_loss: 0.2142 - val_acc: 0.0500\n",
      "Epoch 228/400\n",
      "80/80 [==============================] - 0s 557us/step - loss: 0.1872 - acc: 0.0000e+00 - val_loss: 0.2129 - val_acc: 0.0500\n",
      "Epoch 229/400\n",
      "80/80 [==============================] - 0s 673us/step - loss: 0.1858 - acc: 0.0000e+00 - val_loss: 0.2115 - val_acc: 0.0500\n",
      "Epoch 230/400\n",
      "80/80 [==============================] - 0s 589us/step - loss: 0.1844 - acc: 0.0000e+00 - val_loss: 0.2101 - val_acc: 0.0500\n",
      "Epoch 231/400\n",
      "80/80 [==============================] - 0s 636us/step - loss: 0.1830 - acc: 0.0000e+00 - val_loss: 0.2088 - val_acc: 0.0500\n",
      "Epoch 232/400\n",
      "80/80 [==============================] - 0s 587us/step - loss: 0.1814 - acc: 0.0000e+00 - val_loss: 0.2074 - val_acc: 0.0500\n",
      "Epoch 233/400\n",
      "80/80 [==============================] - 0s 572us/step - loss: 0.1799 - acc: 0.0000e+00 - val_loss: 0.2059 - val_acc: 0.0500\n",
      "Epoch 234/400\n",
      "80/80 [==============================] - 0s 574us/step - loss: 0.1783 - acc: 0.0000e+00 - val_loss: 0.2044 - val_acc: 0.0500\n",
      "Epoch 235/400\n",
      "80/80 [==============================] - 0s 628us/step - loss: 0.1767 - acc: 0.0000e+00 - val_loss: 0.2029 - val_acc: 0.0500\n",
      "Epoch 236/400\n",
      "80/80 [==============================] - 0s 620us/step - loss: 0.1749 - acc: 0.0000e+00 - val_loss: 0.2013 - val_acc: 0.0500\n",
      "Epoch 237/400\n",
      "80/80 [==============================] - 0s 697us/step - loss: 0.1732 - acc: 0.0000e+00 - val_loss: 0.1996 - val_acc: 0.0500\n",
      "Epoch 238/400\n",
      "80/80 [==============================] - 0s 618us/step - loss: 0.1714 - acc: 0.0000e+00 - val_loss: 0.1979 - val_acc: 0.0500\n",
      "Epoch 239/400\n",
      "80/80 [==============================] - 0s 616us/step - loss: 0.1696 - acc: 0.0000e+00 - val_loss: 0.1961 - val_acc: 0.0500\n",
      "Epoch 240/400\n",
      "80/80 [==============================] - 0s 551us/step - loss: 0.1677 - acc: 0.0000e+00 - val_loss: 0.1945 - val_acc: 0.0500\n",
      "Epoch 241/400\n",
      "80/80 [==============================] - 0s 546us/step - loss: 0.1658 - acc: 0.0000e+00 - val_loss: 0.1926 - val_acc: 0.0500\n",
      "Epoch 242/400\n",
      "80/80 [==============================] - 0s 614us/step - loss: 0.1638 - acc: 0.0000e+00 - val_loss: 0.1903 - val_acc: 0.0500\n",
      "Epoch 243/400\n",
      "80/80 [==============================] - 0s 603us/step - loss: 0.1618 - acc: 0.0000e+00 - val_loss: 0.1882 - val_acc: 0.0500\n",
      "Epoch 244/400\n",
      "80/80 [==============================] - 0s 627us/step - loss: 0.1597 - acc: 0.0000e+00 - val_loss: 0.1861 - val_acc: 0.0500\n",
      "Epoch 245/400\n",
      "80/80 [==============================] - 0s 530us/step - loss: 0.1575 - acc: 0.0000e+00 - val_loss: 0.1835 - val_acc: 0.0500\n",
      "Epoch 246/400\n",
      "80/80 [==============================] - 0s 546us/step - loss: 0.1553 - acc: 0.0000e+00 - val_loss: 0.1811 - val_acc: 0.0500\n",
      "Epoch 247/400\n",
      "80/80 [==============================] - 0s 508us/step - loss: 0.1530 - acc: 0.0000e+00 - val_loss: 0.1786 - val_acc: 0.0500\n",
      "Epoch 248/400\n",
      "80/80 [==============================] - 0s 581us/step - loss: 0.1507 - acc: 0.0000e+00 - val_loss: 0.1759 - val_acc: 0.0500\n",
      "Epoch 249/400\n",
      "80/80 [==============================] - 0s 576us/step - loss: 0.1483 - acc: 0.0000e+00 - val_loss: 0.1732 - val_acc: 0.0500\n",
      "Epoch 250/400\n",
      "80/80 [==============================] - 0s 590us/step - loss: 0.1459 - acc: 0.0000e+00 - val_loss: 0.1704 - val_acc: 0.0500\n",
      "Epoch 251/400\n",
      "80/80 [==============================] - 0s 648us/step - loss: 0.1434 - acc: 0.0000e+00 - val_loss: 0.1681 - val_acc: 0.0500\n",
      "Epoch 252/400\n",
      "80/80 [==============================] - 0s 585us/step - loss: 0.1407 - acc: 0.0000e+00 - val_loss: 0.1653 - val_acc: 0.0500\n",
      "Epoch 253/400\n",
      "80/80 [==============================] - 0s 623us/step - loss: 0.1381 - acc: 0.0000e+00 - val_loss: 0.1626 - val_acc: 0.0500\n",
      "Epoch 254/400\n",
      "80/80 [==============================] - 0s 572us/step - loss: 0.1355 - acc: 0.0000e+00 - val_loss: 0.1596 - val_acc: 0.0500\n",
      "Epoch 255/400\n",
      "80/80 [==============================] - 0s 581us/step - loss: 0.1327 - acc: 0.0000e+00 - val_loss: 0.1561 - val_acc: 0.0500\n",
      "Epoch 256/400\n",
      "80/80 [==============================] - 0s 604us/step - loss: 0.1300 - acc: 0.0000e+00 - val_loss: 0.1527 - val_acc: 0.0500\n",
      "Epoch 257/400\n",
      "80/80 [==============================] - 0s 545us/step - loss: 0.1269 - acc: 0.0000e+00 - val_loss: 0.1487 - val_acc: 0.0500\n",
      "Epoch 258/400\n",
      "80/80 [==============================] - 0s 591us/step - loss: 0.1240 - acc: 0.0000e+00 - val_loss: 0.1447 - val_acc: 0.0500\n",
      "Epoch 259/400\n",
      "80/80 [==============================] - 0s 711us/step - loss: 0.1210 - acc: 0.0000e+00 - val_loss: 0.1407 - val_acc: 0.0500\n",
      "Epoch 260/400\n",
      "80/80 [==============================] - 0s 609us/step - loss: 0.1179 - acc: 0.0000e+00 - val_loss: 0.1369 - val_acc: 0.0500\n",
      "Epoch 261/400\n",
      "80/80 [==============================] - 0s 661us/step - loss: 0.1148 - acc: 0.0000e+00 - val_loss: 0.1330 - val_acc: 0.0500\n",
      "Epoch 262/400\n",
      "80/80 [==============================] - 0s 667us/step - loss: 0.1116 - acc: 0.0000e+00 - val_loss: 0.1293 - val_acc: 0.0500\n",
      "Epoch 263/400\n",
      "80/80 [==============================] - 0s 594us/step - loss: 0.1083 - acc: 0.0000e+00 - val_loss: 0.1256 - val_acc: 0.0500\n",
      "Epoch 264/400\n",
      "80/80 [==============================] - 0s 594us/step - loss: 0.1049 - acc: 0.0000e+00 - val_loss: 0.1220 - val_acc: 0.0500\n",
      "Epoch 265/400\n",
      "80/80 [==============================] - 0s 552us/step - loss: 0.1015 - acc: 0.0000e+00 - val_loss: 0.1182 - val_acc: 0.0500\n",
      "Epoch 266/400\n",
      "80/80 [==============================] - 0s 558us/step - loss: 0.0980 - acc: 0.0000e+00 - val_loss: 0.1145 - val_acc: 0.0500\n",
      "Epoch 267/400\n",
      "80/80 [==============================] - 0s 559us/step - loss: 0.0945 - acc: 0.0000e+00 - val_loss: 0.1108 - val_acc: 0.0500\n",
      "Epoch 268/400\n",
      "80/80 [==============================] - 0s 640us/step - loss: 0.0910 - acc: 0.0000e+00 - val_loss: 0.1065 - val_acc: 0.0500\n",
      "Epoch 269/400\n",
      "80/80 [==============================] - 0s 658us/step - loss: 0.0872 - acc: 0.0000e+00 - val_loss: 0.1026 - val_acc: 0.0500\n",
      "Epoch 270/400\n",
      "80/80 [==============================] - 0s 759us/step - loss: 0.0836 - acc: 0.0000e+00 - val_loss: 0.0983 - val_acc: 0.0500\n",
      "Epoch 271/400\n",
      "80/80 [==============================] - 0s 624us/step - loss: 0.0798 - acc: 0.0000e+00 - val_loss: 0.0936 - val_acc: 0.0500\n",
      "Epoch 272/400\n",
      "80/80 [==============================] - 0s 651us/step - loss: 0.0759 - acc: 0.0000e+00 - val_loss: 0.0888 - val_acc: 0.0500\n",
      "Epoch 273/400\n",
      "80/80 [==============================] - 0s 676us/step - loss: 0.0722 - acc: 0.0000e+00 - val_loss: 0.0841 - val_acc: 0.0500\n",
      "Epoch 274/400\n",
      "80/80 [==============================] - 0s 627us/step - loss: 0.0682 - acc: 0.0000e+00 - val_loss: 0.0803 - val_acc: 0.0500\n",
      "Epoch 275/400\n",
      "80/80 [==============================] - 0s 646us/step - loss: 0.0642 - acc: 0.0000e+00 - val_loss: 0.0767 - val_acc: 0.0500\n",
      "Epoch 276/400\n",
      "80/80 [==============================] - 0s 696us/step - loss: 0.0605 - acc: 0.0000e+00 - val_loss: 0.0726 - val_acc: 0.0500\n",
      "Epoch 277/400\n",
      "80/80 [==============================] - 0s 677us/step - loss: 0.0571 - acc: 0.0000e+00 - val_loss: 0.0695 - val_acc: 0.0500\n",
      "Epoch 278/400\n",
      "80/80 [==============================] - 0s 689us/step - loss: 0.0545 - acc: 0.0000e+00 - val_loss: 0.0670 - val_acc: 0.0500\n",
      "Epoch 279/400\n",
      "80/80 [==============================] - 0s 650us/step - loss: 0.0523 - acc: 0.0000e+00 - val_loss: 0.0647 - val_acc: 0.0500\n",
      "Epoch 280/400\n",
      "80/80 [==============================] - 0s 657us/step - loss: 0.0507 - acc: 0.0000e+00 - val_loss: 0.0628 - val_acc: 0.0500\n",
      "Epoch 281/400\n",
      "80/80 [==============================] - 0s 691us/step - loss: 0.0493 - acc: 0.0000e+00 - val_loss: 0.0616 - val_acc: 0.0500\n",
      "Epoch 282/400\n",
      "80/80 [==============================] - 0s 634us/step - loss: 0.0481 - acc: 0.0000e+00 - val_loss: 0.0607 - val_acc: 0.0500\n",
      "Epoch 283/400\n",
      "80/80 [==============================] - 0s 681us/step - loss: 0.0472 - acc: 0.0000e+00 - val_loss: 0.0597 - val_acc: 0.0500\n",
      "Epoch 284/400\n",
      "80/80 [==============================] - 0s 690us/step - loss: 0.0465 - acc: 0.0000e+00 - val_loss: 0.0587 - val_acc: 0.0500\n",
      "Epoch 285/400\n",
      "80/80 [==============================] - 0s 693us/step - loss: 0.0460 - acc: 0.0000e+00 - val_loss: 0.0580 - val_acc: 0.0500\n",
      "Epoch 286/400\n",
      "80/80 [==============================] - 0s 646us/step - loss: 0.0454 - acc: 0.0000e+00 - val_loss: 0.0575 - val_acc: 0.0500\n",
      "Epoch 287/400\n",
      "80/80 [==============================] - 0s 711us/step - loss: 0.0451 - acc: 0.0000e+00 - val_loss: 0.0568 - val_acc: 0.0500\n",
      "Epoch 288/400\n",
      "80/80 [==============================] - 0s 649us/step - loss: 0.0448 - acc: 0.0000e+00 - val_loss: 0.0561 - val_acc: 0.0500\n",
      "Epoch 289/400\n",
      "80/80 [==============================] - 0s 659us/step - loss: 0.0445 - acc: 0.0000e+00 - val_loss: 0.0557 - val_acc: 0.0500\n",
      "Epoch 290/400\n",
      "80/80 [==============================] - 0s 680us/step - loss: 0.0442 - acc: 0.0000e+00 - val_loss: 0.0553 - val_acc: 0.0500\n",
      "Epoch 291/400\n",
      "80/80 [==============================] - 0s 628us/step - loss: 0.0440 - acc: 0.0000e+00 - val_loss: 0.0550 - val_acc: 0.0500\n",
      "Epoch 292/400\n",
      "80/80 [==============================] - 0s 690us/step - loss: 0.0438 - acc: 0.0000e+00 - val_loss: 0.0546 - val_acc: 0.0500\n",
      "Epoch 293/400\n",
      "80/80 [==============================] - 0s 622us/step - loss: 0.0435 - acc: 0.0000e+00 - val_loss: 0.0541 - val_acc: 0.0500\n",
      "Epoch 294/400\n",
      "80/80 [==============================] - 0s 675us/step - loss: 0.0434 - acc: 0.0000e+00 - val_loss: 0.0537 - val_acc: 0.0500\n",
      "Epoch 295/400\n",
      "80/80 [==============================] - 0s 611us/step - loss: 0.0432 - acc: 0.0000e+00 - val_loss: 0.0537 - val_acc: 0.0500\n",
      "Epoch 296/400\n",
      "80/80 [==============================] - 0s 636us/step - loss: 0.0431 - acc: 0.0000e+00 - val_loss: 0.0533 - val_acc: 0.0500\n",
      "Epoch 297/400\n",
      "80/80 [==============================] - 0s 667us/step - loss: 0.0429 - acc: 0.0000e+00 - val_loss: 0.0533 - val_acc: 0.0500\n",
      "Epoch 298/400\n",
      "80/80 [==============================] - 0s 708us/step - loss: 0.0428 - acc: 0.0000e+00 - val_loss: 0.0533 - val_acc: 0.0500\n",
      "Epoch 299/400\n",
      "80/80 [==============================] - 0s 694us/step - loss: 0.0426 - acc: 0.0000e+00 - val_loss: 0.0529 - val_acc: 0.0500\n",
      "Epoch 300/400\n",
      "80/80 [==============================] - 0s 660us/step - loss: 0.0424 - acc: 0.0000e+00 - val_loss: 0.0524 - val_acc: 0.0500\n",
      "Epoch 301/400\n",
      "80/80 [==============================] - 0s 660us/step - loss: 0.0423 - acc: 0.0000e+00 - val_loss: 0.0519 - val_acc: 0.0500\n",
      "Epoch 302/400\n",
      "80/80 [==============================] - 0s 698us/step - loss: 0.0421 - acc: 0.0000e+00 - val_loss: 0.0518 - val_acc: 0.0500\n",
      "Epoch 303/400\n",
      "80/80 [==============================] - 0s 583us/step - loss: 0.0419 - acc: 0.0000e+00 - val_loss: 0.0514 - val_acc: 0.0500\n",
      "Epoch 304/400\n",
      "80/80 [==============================] - 0s 647us/step - loss: 0.0418 - acc: 0.0000e+00 - val_loss: 0.0507 - val_acc: 0.0500\n",
      "Epoch 305/400\n",
      "80/80 [==============================] - 0s 541us/step - loss: 0.0417 - acc: 0.0000e+00 - val_loss: 0.0503 - val_acc: 0.0500\n",
      "Epoch 306/400\n",
      "80/80 [==============================] - 0s 569us/step - loss: 0.0418 - acc: 0.0000e+00 - val_loss: 0.0499 - val_acc: 0.0500\n",
      "Epoch 307/400\n",
      "80/80 [==============================] - 0s 546us/step - loss: 0.0415 - acc: 0.0000e+00 - val_loss: 0.0502 - val_acc: 0.0500\n",
      "Epoch 308/400\n",
      "80/80 [==============================] - 0s 550us/step - loss: 0.0413 - acc: 0.0000e+00 - val_loss: 0.0506 - val_acc: 0.0500\n",
      "Epoch 309/400\n",
      "80/80 [==============================] - 0s 573us/step - loss: 0.0412 - acc: 0.0000e+00 - val_loss: 0.0505 - val_acc: 0.0500\n",
      "Epoch 310/400\n",
      "80/80 [==============================] - 0s 568us/step - loss: 0.0410 - acc: 0.0000e+00 - val_loss: 0.0501 - val_acc: 0.0500\n",
      "Epoch 311/400\n",
      "80/80 [==============================] - 0s 566us/step - loss: 0.0409 - acc: 0.0000e+00 - val_loss: 0.0497 - val_acc: 0.0500\n",
      "Epoch 312/400\n",
      "80/80 [==============================] - 0s 538us/step - loss: 0.0408 - acc: 0.0000e+00 - val_loss: 0.0496 - val_acc: 0.0500\n",
      "Epoch 313/400\n",
      "80/80 [==============================] - 0s 550us/step - loss: 0.0406 - acc: 0.0000e+00 - val_loss: 0.0495 - val_acc: 0.0500\n",
      "Epoch 314/400\n",
      "80/80 [==============================] - 0s 537us/step - loss: 0.0405 - acc: 0.0000e+00 - val_loss: 0.0496 - val_acc: 0.0500\n",
      "Epoch 315/400\n",
      "80/80 [==============================] - 0s 559us/step - loss: 0.0404 - acc: 0.0000e+00 - val_loss: 0.0494 - val_acc: 0.0500\n",
      "Epoch 316/400\n",
      "80/80 [==============================] - 0s 581us/step - loss: 0.0403 - acc: 0.0000e+00 - val_loss: 0.0492 - val_acc: 0.0500\n",
      "Epoch 317/400\n",
      "80/80 [==============================] - 0s 549us/step - loss: 0.0402 - acc: 0.0000e+00 - val_loss: 0.0492 - val_acc: 0.0500\n",
      "Epoch 318/400\n",
      "80/80 [==============================] - 0s 637us/step - loss: 0.0402 - acc: 0.0000e+00 - val_loss: 0.0486 - val_acc: 0.0500\n",
      "Epoch 319/400\n",
      "80/80 [==============================] - 0s 646us/step - loss: 0.0399 - acc: 0.0000e+00 - val_loss: 0.0486 - val_acc: 0.0500\n",
      "Epoch 320/400\n",
      "80/80 [==============================] - 0s 635us/step - loss: 0.0398 - acc: 0.0000e+00 - val_loss: 0.0481 - val_acc: 0.0500\n",
      "Epoch 321/400\n",
      "80/80 [==============================] - 0s 618us/step - loss: 0.0398 - acc: 0.0000e+00 - val_loss: 0.0476 - val_acc: 0.0500\n",
      "Epoch 322/400\n",
      "80/80 [==============================] - 0s 574us/step - loss: 0.0396 - acc: 0.0000e+00 - val_loss: 0.0475 - val_acc: 0.0500\n",
      "Epoch 323/400\n",
      "80/80 [==============================] - 0s 593us/step - loss: 0.0395 - acc: 0.0000e+00 - val_loss: 0.0476 - val_acc: 0.0500\n",
      "Epoch 324/400\n",
      "80/80 [==============================] - 0s 591us/step - loss: 0.0394 - acc: 0.0000e+00 - val_loss: 0.0477 - val_acc: 0.0500\n",
      "Epoch 325/400\n",
      "80/80 [==============================] - 0s 597us/step - loss: 0.0393 - acc: 0.0000e+00 - val_loss: 0.0475 - val_acc: 0.0500\n",
      "Epoch 326/400\n",
      "80/80 [==============================] - 0s 606us/step - loss: 0.0391 - acc: 0.0000e+00 - val_loss: 0.0476 - val_acc: 0.0500\n",
      "Epoch 327/400\n",
      "80/80 [==============================] - 0s 633us/step - loss: 0.0391 - acc: 0.0000e+00 - val_loss: 0.0474 - val_acc: 0.0500\n",
      "Epoch 328/400\n",
      "80/80 [==============================] - 0s 627us/step - loss: 0.0389 - acc: 0.0000e+00 - val_loss: 0.0468 - val_acc: 0.0500\n",
      "Epoch 329/400\n",
      "80/80 [==============================] - 0s 549us/step - loss: 0.0388 - acc: 0.0000e+00 - val_loss: 0.0465 - val_acc: 0.0500\n",
      "Epoch 330/400\n",
      "80/80 [==============================] - 0s 605us/step - loss: 0.0388 - acc: 0.0000e+00 - val_loss: 0.0465 - val_acc: 0.0500\n",
      "Epoch 331/400\n",
      "80/80 [==============================] - 0s 591us/step - loss: 0.0386 - acc: 0.0000e+00 - val_loss: 0.0462 - val_acc: 0.0500\n",
      "Epoch 332/400\n",
      "80/80 [==============================] - 0s 633us/step - loss: 0.0385 - acc: 0.0000e+00 - val_loss: 0.0461 - val_acc: 0.0500\n",
      "Epoch 333/400\n",
      "80/80 [==============================] - 0s 557us/step - loss: 0.0385 - acc: 0.0000e+00 - val_loss: 0.0465 - val_acc: 0.0500\n",
      "Epoch 334/400\n",
      "80/80 [==============================] - 0s 614us/step - loss: 0.0383 - acc: 0.0000e+00 - val_loss: 0.0464 - val_acc: 0.0500\n",
      "Epoch 335/400\n",
      "80/80 [==============================] - 0s 594us/step - loss: 0.0382 - acc: 0.0000e+00 - val_loss: 0.0465 - val_acc: 0.0500\n",
      "Epoch 336/400\n",
      "80/80 [==============================] - 0s 579us/step - loss: 0.0381 - acc: 0.0000e+00 - val_loss: 0.0463 - val_acc: 0.0500\n",
      "Epoch 337/400\n",
      "80/80 [==============================] - 0s 740us/step - loss: 0.0380 - acc: 0.0000e+00 - val_loss: 0.0463 - val_acc: 0.0500\n",
      "Epoch 338/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0379 - acc: 0.0000e+00 - val_loss: 0.0462 - val_acc: 0.0500\n",
      "Epoch 339/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0378 - acc: 0.0000e+00 - val_loss: 0.0461 - val_acc: 0.0500\n",
      "Epoch 340/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0378 - acc: 0.0000e+00 - val_loss: 0.0461 - val_acc: 0.0500\n",
      "Epoch 341/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0377 - acc: 0.0000e+00 - val_loss: 0.0459 - val_acc: 0.0500\n",
      "Epoch 342/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0376 - acc: 0.0000e+00 - val_loss: 0.0456 - val_acc: 0.0500\n",
      "Epoch 343/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0375 - acc: 0.0000e+00 - val_loss: 0.0457 - val_acc: 0.0500\n",
      "Epoch 344/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0374 - acc: 0.0000e+00 - val_loss: 0.0453 - val_acc: 0.0500\n",
      "Epoch 345/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0373 - acc: 0.0000e+00 - val_loss: 0.0450 - val_acc: 0.0500\n",
      "Epoch 346/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0372 - acc: 0.0000e+00 - val_loss: 0.0450 - val_acc: 0.0500\n",
      "Epoch 347/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0371 - acc: 0.0000e+00 - val_loss: 0.0448 - val_acc: 0.0500\n",
      "Epoch 348/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0369 - acc: 0.0000e+00 - val_loss: 0.0441 - val_acc: 0.0500\n",
      "Epoch 349/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0369 - acc: 0.0000e+00 - val_loss: 0.0432 - val_acc: 0.0500\n",
      "Epoch 350/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0369 - acc: 0.0000e+00 - val_loss: 0.0430 - val_acc: 0.0500\n",
      "Epoch 351/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0368 - acc: 0.0000e+00 - val_loss: 0.0433 - val_acc: 0.0500\n",
      "Epoch 352/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0366 - acc: 0.0000e+00 - val_loss: 0.0436 - val_acc: 0.0500\n",
      "Epoch 353/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0365 - acc: 0.0000e+00 - val_loss: 0.0438 - val_acc: 0.0500\n",
      "Epoch 354/400\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.0364 - acc: 0.0000e+00 - val_loss: 0.0442 - val_acc: 0.0500\n",
      "Epoch 355/400\n",
      "80/80 [==============================] - 0s 861us/step - loss: 0.0364 - acc: 0.0000e+00 - val_loss: 0.0445 - val_acc: 0.0500\n",
      "Epoch 356/400\n",
      "80/80 [==============================] - 0s 617us/step - loss: 0.0365 - acc: 0.0000e+00 - val_loss: 0.0449 - val_acc: 0.0500\n",
      "Epoch 357/400\n",
      "80/80 [==============================] - 0s 655us/step - loss: 0.0363 - acc: 0.0000e+00 - val_loss: 0.0444 - val_acc: 0.0500\n",
      "Epoch 358/400\n",
      "80/80 [==============================] - 0s 592us/step - loss: 0.0361 - acc: 0.0000e+00 - val_loss: 0.0433 - val_acc: 0.0500\n",
      "Epoch 359/400\n",
      "80/80 [==============================] - 0s 608us/step - loss: 0.0361 - acc: 0.0000e+00 - val_loss: 0.0425 - val_acc: 0.0500\n",
      "Epoch 360/400\n",
      "80/80 [==============================] - 0s 561us/step - loss: 0.0359 - acc: 0.0000e+00 - val_loss: 0.0423 - val_acc: 0.0500\n",
      "Epoch 361/400\n",
      "80/80 [==============================] - 0s 521us/step - loss: 0.0359 - acc: 0.0000e+00 - val_loss: 0.0420 - val_acc: 0.0500\n",
      "Epoch 362/400\n",
      "80/80 [==============================] - 0s 541us/step - loss: 0.0358 - acc: 0.0000e+00 - val_loss: 0.0423 - val_acc: 0.0500\n",
      "Epoch 363/400\n",
      "80/80 [==============================] - 0s 570us/step - loss: 0.0357 - acc: 0.0000e+00 - val_loss: 0.0426 - val_acc: 0.0500\n",
      "Epoch 364/400\n",
      "80/80 [==============================] - 0s 559us/step - loss: 0.0356 - acc: 0.0000e+00 - val_loss: 0.0427 - val_acc: 0.0500\n",
      "Epoch 365/400\n",
      "80/80 [==============================] - 0s 500us/step - loss: 0.0356 - acc: 0.0000e+00 - val_loss: 0.0430 - val_acc: 0.0500\n",
      "Epoch 366/400\n",
      "80/80 [==============================] - 0s 522us/step - loss: 0.0355 - acc: 0.0000e+00 - val_loss: 0.0424 - val_acc: 0.0500\n",
      "Epoch 367/400\n",
      "80/80 [==============================] - 0s 554us/step - loss: 0.0354 - acc: 0.0000e+00 - val_loss: 0.0424 - val_acc: 0.0500\n",
      "Epoch 368/400\n",
      "80/80 [==============================] - 0s 584us/step - loss: 0.0354 - acc: 0.0000e+00 - val_loss: 0.0427 - val_acc: 0.0500\n",
      "Epoch 369/400\n",
      "80/80 [==============================] - 0s 521us/step - loss: 0.0352 - acc: 0.0000e+00 - val_loss: 0.0419 - val_acc: 0.0500\n",
      "Epoch 370/400\n",
      "80/80 [==============================] - 0s 532us/step - loss: 0.0352 - acc: 0.0000e+00 - val_loss: 0.0413 - val_acc: 0.0500\n",
      "Epoch 371/400\n",
      "80/80 [==============================] - 0s 528us/step - loss: 0.0350 - acc: 0.0000e+00 - val_loss: 0.0413 - val_acc: 0.0500\n",
      "Epoch 372/400\n",
      "80/80 [==============================] - 0s 579us/step - loss: 0.0350 - acc: 0.0000e+00 - val_loss: 0.0417 - val_acc: 0.0500\n",
      "Epoch 373/400\n",
      "80/80 [==============================] - 0s 555us/step - loss: 0.0349 - acc: 0.0000e+00 - val_loss: 0.0415 - val_acc: 0.0500\n",
      "Epoch 374/400\n",
      "80/80 [==============================] - 0s 527us/step - loss: 0.0348 - acc: 0.0000e+00 - val_loss: 0.0410 - val_acc: 0.0500\n",
      "Epoch 375/400\n",
      "80/80 [==============================] - 0s 645us/step - loss: 0.0347 - acc: 0.0000e+00 - val_loss: 0.0406 - val_acc: 0.0500\n",
      "Epoch 376/400\n",
      "80/80 [==============================] - 0s 529us/step - loss: 0.0347 - acc: 0.0000e+00 - val_loss: 0.0405 - val_acc: 0.0500\n",
      "Epoch 377/400\n",
      "80/80 [==============================] - 0s 523us/step - loss: 0.0346 - acc: 0.0000e+00 - val_loss: 0.0408 - val_acc: 0.0500\n",
      "Epoch 378/400\n",
      "80/80 [==============================] - 0s 609us/step - loss: 0.0344 - acc: 0.0000e+00 - val_loss: 0.0413 - val_acc: 0.0500\n",
      "Epoch 379/400\n",
      "80/80 [==============================] - 0s 529us/step - loss: 0.0344 - acc: 0.0000e+00 - val_loss: 0.0419 - val_acc: 0.0500\n",
      "Epoch 380/400\n",
      "80/80 [==============================] - 0s 551us/step - loss: 0.0343 - acc: 0.0000e+00 - val_loss: 0.0418 - val_acc: 0.0500\n",
      "Epoch 381/400\n",
      "80/80 [==============================] - 0s 502us/step - loss: 0.0343 - acc: 0.0000e+00 - val_loss: 0.0412 - val_acc: 0.0500\n",
      "Epoch 382/400\n",
      "80/80 [==============================] - 0s 597us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0409 - val_acc: 0.0500\n",
      "Epoch 383/400\n",
      "80/80 [==============================] - 0s 592us/step - loss: 0.0341 - acc: 0.0000e+00 - val_loss: 0.0407 - val_acc: 0.0500\n",
      "Epoch 384/400\n",
      "80/80 [==============================] - 0s 544us/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0404 - val_acc: 0.0500\n",
      "Epoch 385/400\n",
      "80/80 [==============================] - 0s 713us/step - loss: 0.0339 - acc: 0.0000e+00 - val_loss: 0.0406 - val_acc: 0.0500\n",
      "Epoch 386/400\n",
      "80/80 [==============================] - 0s 597us/step - loss: 0.0339 - acc: 0.0000e+00 - val_loss: 0.0409 - val_acc: 0.0500\n",
      "Epoch 387/400\n",
      "80/80 [==============================] - 0s 533us/step - loss: 0.0338 - acc: 0.0000e+00 - val_loss: 0.0407 - val_acc: 0.0500\n",
      "Epoch 388/400\n",
      "80/80 [==============================] - 0s 610us/step - loss: 0.0337 - acc: 0.0000e+00 - val_loss: 0.0409 - val_acc: 0.0500\n",
      "Epoch 389/400\n",
      "80/80 [==============================] - 0s 638us/step - loss: 0.0336 - acc: 0.0000e+00 - val_loss: 0.0405 - val_acc: 0.0500\n",
      "Epoch 390/400\n",
      "80/80 [==============================] - 0s 632us/step - loss: 0.0335 - acc: 0.0000e+00 - val_loss: 0.0401 - val_acc: 0.0500\n",
      "Epoch 391/400\n",
      "80/80 [==============================] - 0s 618us/step - loss: 0.0334 - acc: 0.0000e+00 - val_loss: 0.0401 - val_acc: 0.0500\n",
      "Epoch 392/400\n",
      "80/80 [==============================] - 0s 585us/step - loss: 0.0334 - acc: 0.0000e+00 - val_loss: 0.0399 - val_acc: 0.0500\n",
      "Epoch 393/400\n",
      "80/80 [==============================] - 0s 633us/step - loss: 0.0333 - acc: 0.0000e+00 - val_loss: 0.0395 - val_acc: 0.0500\n",
      "Epoch 394/400\n",
      "80/80 [==============================] - 0s 563us/step - loss: 0.0332 - acc: 0.0000e+00 - val_loss: 0.0390 - val_acc: 0.0500\n",
      "Epoch 395/400\n",
      "80/80 [==============================] - 0s 516us/step - loss: 0.0332 - acc: 0.0000e+00 - val_loss: 0.0389 - val_acc: 0.0500\n",
      "Epoch 396/400\n",
      "80/80 [==============================] - 0s 549us/step - loss: 0.0331 - acc: 0.0000e+00 - val_loss: 0.0389 - val_acc: 0.0500\n",
      "Epoch 397/400\n",
      "80/80 [==============================] - 0s 570us/step - loss: 0.0330 - acc: 0.0000e+00 - val_loss: 0.0391 - val_acc: 0.0500\n",
      "Epoch 398/400\n",
      "80/80 [==============================] - 0s 563us/step - loss: 0.0330 - acc: 0.0000e+00 - val_loss: 0.0396 - val_acc: 0.0500\n",
      "Epoch 399/400\n",
      "80/80 [==============================] - 0s 550us/step - loss: 0.0330 - acc: 0.0000e+00 - val_loss: 0.0400 - val_acc: 0.0500\n",
      "Epoch 400/400\n",
      "80/80 [==============================] - 0s 492us/step - loss: 0.0328 - acc: 0.0000e+00 - val_loss: 0.0399 - val_acc: 0.0500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xtrain, ytrain, epochs=400, validation_data=(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f203bef0438>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAF3hJREFUeJzt3X+MHGd9x/H39xwbtBAuP3ylaezbDZWpmmJaolNKgUKqC9Sxaru/RJMuaiCEFW1TJVBapdoqQKr9I0VFDiiFblsgoC1JaGt6bo0MdVMhVU0ahzp2fhBypHcXuyEJCbk0WrW2k2//mNmwt9m929ud3dnZ5/OSrN19du72m8ncZ595ZuYZc3dERGT8TaRdgIiIDIcCX0QkEAp8EZFAKPBFRAKhwBcRCYQCX0QkEAp8EZFAKPBFRAKhwBcRCcQZaX3w5s2bvVAopPXxIiKZdO+9937f3ad6+dnUAr9QKHD48OG0Pl5EJJPMbLHXn9WQjohIIBT4IiKBUOCLiARCgS8iEggFvohIIBT4IiKBUOCLiARCgS8iEggFvgxV7ViNwt4CEx+foLC3QO1YLe2SRIKR2pW2Ep7asRql/SXqp+oALC4vUtpfAqC4vZhmaSJBUA+/R+qprl/5UPmlsG+on6pTPlROqSKRsKwZ+Gb2OTN70szu7/C+mdmnzGzezI6a2UXJlzlaGj3VxeVFHH+pp6rQX93S8tK62kUkWd308L8A7Fjl/cuAbfG/EvCZ/ssabeqp9mZ6cnpd7bKS9iqlX2sGvrt/E3hmlUX2AF/0yF3AWWZ2XlIFjiL1VHtTma2Q25hb0ZbbmKMyW0mpouzQXqUkIYkx/POBx5peH4/bxpZ6qr0pbi9S3VUlP5nHMPKTeaq7qjpg2wXtVUoShnqWjpmViIZ9mJ7ObjhWZisrzjYB9VS7VdxeVMD3QHuVkoQkevgngK1Nr7fEbS/j7lV3n3H3mampnm7YMhLUU5Vh016lJCGJHv4ccI2Z3Qb8LLDs7o8n8HtHmnqqMkzaq5QkrBn4ZvZl4BJgs5kdBz4KbARw988CB4CdwDxQB943qGJFQtXoXJQPlVlaXmJ6cprKbEWdDlkXc/dUPnhmZsZ1T1sRkfUxs3vdfaaXn9WVtiIigVDgi4gEQoEvIhIIBb6ISCAU+CIigVDg96pWg0IBJiaix5rmNOmK1ptIahT4vajVoFSCxUVwjx5LJYXXWrTe+qMvS+mTzsPvRaEQhVWrfB4WFoZdTXZovfWu8WVZb5pALZeDahWKuvgqJP2ch6/A78XERNRDbWUGL744/HqyQuutd/qylJguvBq2TjN9ZngG0KHQeuvdUodZMTu1i7ShwO9FpRLtTjfL5aJ26UzrrXf6spQEKPB7USxGY6f5fDQckc9rLLUbWm+905elJEBj+CJZUatBuRwN40xPR2GvL8vg9DOGP9Q7XolIH4pFBbz0RUM6IiKBUOCLiARCgS8iEggFvohIIBT4IiKBUOCLiARCgS8iEggFvohIIBT4IiKBUOCLiARCgS8iEggFvohIIBT4IiKBUOCLiARCgS8iEggFvohIIBT4IiKBUOCLiASiq8A3sx1m9rCZzZvZ9W3enzazO83sP83sqJntTL5UERHpx5qBb2YbgFuAy4ALgSvM7MKWxf4YuMPd3wRcDvx50oWKiEh/uunhXwzMu/uj7n4SuA3Y07KMA6+Jn08C/51ciSIikoRuAv984LGm18fjtmYfA95jZseBA8DvtftFZlYys8Nmdvipp57qoVwREelVUgdtrwC+4O5bgJ3Al8zsZb/b3avuPuPuM1NTUwl9tIiIdKObwD8BbG16vSVua/Z+4A4Ad/934JXA5iQKFBGRZHQT+PcA28zsAjPbRHRQdq5lmSVgFsDMfpIo8DVmIyIyQtYMfHc/DVwDHAQeIjob5wEzu9HMdseL/T7wATO7D/gy8F5390EVLSIi63dGNwu5+wGig7HNbTc0PX8QeGuypYmISJJ0pa2ISCAU+CIigVDgi4gEQoEvIhIIBb6ISCAU+CIigVDgi4gEQoEvIhIIBb6ISCAU+CIigVDgi4gEQoEvIhIIBb6ISCAU+FlUq0GhABMT0WOtlnZFIpIBXU2PLCOkVoNSCer16PXiYvQaoFhMry4RGXnq4WdNufzDsG+o16N2EZFVKPCzZmmJ2nYoXAcTH40ea9ujdhGR1WhIJ2Nq7ziH0luepr4per14FpR2AeeegwZ0RGQ16uFnTPlSXgr7hvqmqF1EZDUK/IxZOv3MutpFRBoU+BkzPTm9rnYRkQYFfsZUZivkNuZWtOU25qjMVlKqSESyQoGfMcXtRaq7quQn8xhGfjJPdVeV4nYdshWR1Zm7p/LBMzMzfvjw4VQ+W0Qkq8zsXnef6eVn1cMXEQmEAl9EJBAKfBGRQCjwRUQCocAXEQmEAl9EJBAKfBGRQHQV+Ga2w8weNrN5M7u+wzLvNrMHzewBM/ubZMsUEZF+rTk9spltAG4B3gkcB+4xszl3f7BpmW3AHwFvdfcfmNmPDKpgERHpTTc9/IuBeXd/1N1PArcBe1qW+QBwi7v/AMDdn0y2TBER6Vc3gX8+8FjT6+NxW7PXA683s38zs7vMbEdSBYqIZFntWI3C3gITH5+gsLdA7VgttVqSuuPVGcA24BJgC/BNM9vu7s82L2RmJaAEMD2t6XxFZLzVjtUo7buKup8EYHF5kdK+qwBSmfCwmx7+CWBr0+stcVuz48Ccu59y9/8CvkP0BbCCu1fdfcbdZ6ampnqtWVI0Sr0VkVFXnrv2pbBvqPtJynPXplJPN4F/D7DNzC4ws03A5cBcyzJfJerdY2abiYZ4Hk2wThkBtWM1SvtLLC4v4njUW9lfUuiLdLB06ul1tQ/amoHv7qeBa4CDwEPAHe7+gJndaGa748UOAk+b2YPAncAfuHs6/0UyMOVDZeqn6iva6qfqlA+VU6pIZLRNL6+vfdC6GsN39wPAgZa2G5qeO/Dh+J+MqaXlxXW1i4SucuRcSm95mvqmH7blTkbtadCVttK16ec3rKtdJHTFq2+menAj+WfBHPLPQvXgRopX35xKPQp86Vrl4AvkVh5/inorB19IpyCRUVcsUvzQ51nYl+fFG42FfXmKH/o8FNO5JWlSp2VKAIrP5WH/IuVZWJqMxiErh+J2EWmvWEwt4Fsp8KV7lQrFUonisaYDt7kcVCvp1SQiXdOQjnSvWIRqFfJ5MIseq9WR6b2IyOrUw5f1GaHdUxFZH/XwRUQCocAXEQmEAl+CormAJGQaw5dgNOYCakwP0ZgLCNKZuVBk2NTDl2BoLiAJnQJfgrG0vLSudpFxo8CXYExPtr/pTqd2kXGjwJdgVGYr5GzTiracbaIyqyuFJQwKfAlG8ShU53zlzIVzTvFo2pWJDIdFU9kP38zMjB8+fDiVz5ZAFQqw2Gbu/nweFhaGXY1IT8zsXnef6eVn1cOXcCx1ODjbqb2FzuGXrFPgSzimOxyc7dTeRPfzlXGgwJdwVCrRdM7NcrmofQ06h1/GgQJfwtHH9M46h1/GgQJfMqXvcfRiMTpA++KL0WOXUz3rHH4ZBwp8yYw0x9ErsxVyG1cOB+U25nQOv2SKAl8yI81x9OL2ItVdVfKTeQwjP5mnuquqSdckUzRbpmRG2uPoxaNQ3AssAdPAFLB9KB8tkgj18CUzUh1Hr9WgVIou3HKPHkulqF0kIxT4khmpjqOXy1BfOZxEvR61i2SEAl8yI9Vx9D6v0hUZBRrDl0xJbRx9err9PDxdXKUrMirUw5fsSHMcvY+rdEXzEI0KBb5kR5rj6H1cpRs6zUM0OjQ9smTHxETUs29lFl05KyOpsLfA4vLLh8Pyk3kWrlsYfkEZp+mRJQx9zHYp6Un7+gn5oa4C38x2mNnDZjZvZtevstyvmZmbWU/fPiKr0jh6JmkeotGxZuCb2QbgFuAy4ELgCjO7sM1yZwLXAncnXaQIoHH0jMr6PETjdMC5mx7+xcC8uz/q7ieB24A9bZb7E+Am4H8TrE9kpR5nu5T0ZHkeonE74NxN4J8PPNb0+njc9hIzuwjY6u7/lGBtIjImikdhYS+8+PHoMSs3jh+3G9/0feGVmU0AnwTe28WyJaAEMK0DbSJhaFw/0TiltnH9BIz8Htq4HXDupod/Atja9HpL3NZwJvAG4F/NbAF4MzDX7sCtu1fdfcbdZ6ampnqvWkSyI8PzEI3bAeduAv8eYJuZXWBmm4DLgbnGm+6+7O6b3b3g7gXgLmC3u+skexHJ9DxEWT/g3GrNwHf308A1wEHgIeAOd3/AzG40s92DLlBEMi7D108Utxepnn0l+ec3YA755zdQPfvKTBxwbqerMXx3PwAcaGm7ocOyl/RfloiMjUpl5Rg+ZOf6iVqN4kdupVh/IW54AXK3wmveOvLHH9rRlbYiMlhZvn4iw8cf2tFcOiIinYzg/E2aS0dEZBAyfPyhHQW+iEgnYzZ/kwJfRMZaX3PhZPn4Qxu6xaGIjK3GXDiN6REac+EA3Z9aWSxmNuBbqYcvImNr3ObC6ZcCX0TG1rjNhdMvBb6IjK1xmwunXwp8ERlblVfsJHdqZVvuVNQeIgW+SADG6a5N61G86QDVOcg/SzQXzrNQnYvaQ6SzdETGXCJnqmTV0hJFh+KxlnbTGL6IjKGgz1QZsytl+6XAFxlzS8uL62ofK2N2pWy/FPgBCnU8N1TTz29YV/tYGbMrZfulwA9M7ViN0r6rWFxexPFoPHffVQr9MVY5+AK5kyvbciej9iAUi7CwEM1uubAQbNiDAj845blrqfvKv/66n6Q8d21KFcmgFZ/LU93fcqbK/qhdwqKzdAKzdOppsA7tMp4qFYqlEsVjLXecqoY5jh0y9fADM728vnYZAxrHllh2A79Wg0IhuiNNoRC9ljVVjpzbfjz3yLnpFCTDoXFsIauBX6tFN0VeXIxuP7a4GL1W6K+pePXNVA9uXDmee3AjxatvTrs0ERmwbN7TtlCIQr5VPh/1XmR1tVp0E+alpegClEpFPT6RjOjnnrbZDPyJCWpvcMqzsDQZjT9XDkHx/vRuLCwiMgzB3cS89o5zKO2CxbPALXos7YraM0HHH0QkBZkM/PKlUN+0sq2+KWofeTr+ICIpyWTgL51+Zl3tI6VchvrKiayo16N2EWlPe8WJyGTgZ/ouNksdpmXt1C4yCtIMXO0VJyaTgV+ZrZDbuHIGvNzGHJXZDFw5qOlaJWvSDlztFScmk4Ff3F6kuqtKfjKPYeQn81R3Vdd3M4e0eiyarlWyJu3A1V5xYrJ5Wma/Gj2WeuvcIkO63FznwUuWTExEPftWNqTToHXdzQrBnZbZt5R7LLU3QuE6mPho9Fh741A+VqQ3aQ9Daq84MV0FvpntMLOHzWzezK5v8/6HzexBMztqZofMbLTnXU1xF7Fxf9EV89HvL2k+ehldaQeuJn9LzJpDOma2AfgO8E7gOHAPcIW7P9i0zC8Ad7t73cx+G7jE3X9jtd+b6pBOiruIhb0FFtvcWi4/mWfhusF+tkjPNAw5MgY9pHMxMO/uj7r7SeA2YE/zAu5+p7s3xkjuArb0UszQpNhjWVpuvxfRqV3GSJbPJddsm2Ohm8A/H3is6fXxuK2T9wNf66eogUtxFzHT1xBI79I+tTHjdB/mZCR60NbM3gPMAJ/o8H7JzA6b2eGnnnoqyY9ev5R6LJm+hkB6l/apjRmm417J6SbwTwBbm15vidtWMLNLgTKw293/r90vcvequ8+4+8zU1FQv9WZeItcQSPZk/FzyNHvY5UNl6qdWflnWT9UpH9KX5Xp1c0/be4BtZnYBUdBfDvxm8wJm9ibgL4Ad7v5k4lWOmeL2ogI+NNPT7U8UyMAV1o0ediN0Gz1sYCjbsY57JWfNHr67nwauAQ4CDwF3uPsDZnajme2OF/sE8GrgK2Z2xMzmBlaxSBalfWpjH9LuYeu4V3K66eHj7geAAy1tNzQ9z8LExCLpaRwjyuCpjWn3sCuzlRV7GKDjXr0K80pbkTRk9NTGtHvYOu6VnK56+CISrlHoYeu4VzKC7eHrvF6R7qiHPT6CnC2z9awDiHos2ohFZNRptsx1SvusAxGRNAQZ+GmfdSAikoYgAz/tsw5ERNIQZOBrPhsRCVGQga+zDkQkREGepSMiklU6S0dERNakwBcRCYQCX0QkEAp8EZFAKPBFRAKhwBcRCYQCX0QkEAp8EZFAKPBFRAKhwBcZEt10R9KmWxyKDEHrTXcWlxcp7S8BaA4nGRr18EWGQDfdkVGgwBcZAt10R0aBAl9kCHTTHRkFCnyRIdBNd2QUKPBFhkA33ZFRoBugiIhkiG6AIiIia1Lgi4gEQoEvIhIIBb6ISCAU+CIigVDgi4gEQoEvIhKI1M7DN7OngMUEftVm4PsJ/J5BGeX6VFtvRrk2GO36VFtvmmvLu/tUL78ktcBPipkd7vUihGEY5fpUW29GuTYY7fpUW2+Sqk1DOiIigVDgi4gEYhwCv5p2AWsY5fpUW29GuTYY7fpUW28SqS3zY/giItKdcejhi4hIFzIT+Ga2w8weNrN5M7u+zfuvMLPb4/fvNrPCkOraamZ3mtmDZvaAmV3bZplLzGzZzI7E/24YRm1Nn79gZsfiz37ZnNQW+VS87o6a2UVDqusnmtbJETN7zsyua1lmaOvOzD5nZk+a2f1NbeeY2TfM7JH48ewOP3tlvMwjZnblEOv7hJl9O/7/ts/Mzurws6tuAwOq7WNmdqLp/93ODj+76t/2gGq7vamuBTM70uFnB73e2ubHwLY7dx/5f8AG4LvA64BNwH3AhS3L/A7w2fj55cDtQ6rtPOCi+PmZwHfa1HYJ8I8prr8FYPMq7+8EvgYY8Gbg7pT+H3+P6BzjVNYd8HbgIuD+prY/Ba6Pn18P3NTm584BHo0fz46fnz2k+t4FnBE/v6ldfd1sAwOq7WPAR7r4/77q3/Ygamt5/8+AG1Jab23zY1DbXVZ6+BcD8+7+qLufBG4D9rQsswe4NX7+t8CsmdmgC3P3x939W/Hz/wEeAs4f9OcmbA/wRY/cBZxlZucNuYZZ4LvunsTFeD1x928Cz7Q0N29XtwK/3OZHfxH4hrs/4+4/AL4B7BhGfe7+dXc/Hb+8C9iS9Od2o8O660Y3f9sDqy3OiHcDX07yM7u1Sn4MZLvLSuCfDzzW9Po4Lw/Vl5aJ/wCWgXOHUl0sHkZ6E3B3m7d/zszuM7OvmdlPDbMuwIGvm9m9ZlZq834363fQLqfzH12a6+617v54/Px7wGvbLDMK6w/gKqI9tXbW2gYG5Zp4uOlzHYYl0l53Pw884e6PdHh/aOutJT8Gst1lJfBHnpm9Gvg74Dp3f67l7W8RDVX8NPBp4KtDLu9t7n4RcBnwu2b29iF//qrMbBOwG/hKm7fTXncv8Wg/eiRPazOzMnAaqHVYJI1t4DPAjwM/AzxONHQyaq5g9d79UNbbavmR5HaXlcA/AWxter0lbmu7jJmdAUwCTw+jODPbSPQ/q+buf9/6vrs/5+7Px88PABvNbPMwaos/80T8+CSwj2g3ulk363eQLgO+5e5PtL6R9roDnmgMb8WPT7ZZJtX1Z2bvBX4JKMbh8DJdbAOJc/cn3P0Fd38R+MsOn5nauotz4leB2zstM4z11iE/BrLdZSXw7wG2mdkFcW/wcmCuZZk5oHGU+teBf+m08ScpHgP8a+Ahd/9kh2V+tHE8wcwuJlrvw/oyepWZndl4TnSQ7/6WxeaA37LIm4Hlpt3JYejYy0pz3cWat6srgX9os8xB4F1mdnY8bPGuuG3gzGwH8IfAbnevd1imm21gELU1Hwf6lQ6f2c3f9qBcCnzb3Y+3e3MY622V/BjMdjeoo88DOJq9k+gI9neBctx2I9GGDvBKoiGBeeA/gNcNqa63Ee1uHQWOxP92Ah8EPhgvcw3wANEZCHcBbxnientd/Ln3xTU01l1zfQbcEq/bY8DMEOt7FVGATza1pbLuiL50HgdOEY2Hvp/oONAh4BHgn4Fz4mVngL9q+tmr4m1vHnjfEOubJxrHbWx7jTPVfgw4sNo2MITavhRvT0eJAuy81tri1y/72x50bXH7FxrbWdOyw15vnfJjINudrrQVEQlEVoZ0RESkTwp8EZFAKPBFRAKhwBcRCYQCX0QkEAp8EZFAKPBFRAKhwBcRCcT/A6Lop1qV+XhxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(20), results, c='r')\n",
    "plt.scatter(range(20), ytest, c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
